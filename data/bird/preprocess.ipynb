{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "# Enable inline plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Text Standardization\n",
    "    # Convert `question` and `evidence` fields to lowercase\n",
    "    df['question'] = df['question'].str.lower()\n",
    "    df['evidence'] = df['evidence'].str.lower()\n",
    "    # Check standardized text\n",
    "    df[['question', 'evidence']].head()\n",
    "    # Data Cleaning\n",
    "    # Handle missing values in `evidence`\n",
    "    df['evidence'] = df['evidence'].fillna('missing')\n",
    "    # Remove duplicate questions\n",
    "    df.drop_duplicates(subset=['question'], inplace=True)\n",
    "    # Feature Engineering\n",
    "    # Compute SQL query length\n",
    "    df['sql_length'] = df['SQL'].apply(lambda x: len(x) if pd.notnull(x) else 0)\n",
    "    # Encode `difficulty` into numeric values\n",
    "    difficulty_mapping = {\"simple\": 1, \"moderate\": 2, \"challenging\": 3}\n",
    "    df['difficulty_encoded'] = df['difficulty'].map(difficulty_mapping)\n",
    "    # Compute question word length\n",
    "    df['question_length'] = df['question'].apply(lambda x: len(x.split()))\n",
    "    # Display new features\n",
    "    df[['sql_length', 'difficulty_encoded', 'question_length']].head()\n",
    "    # Normalize Length Features\n",
    "    # Normalize `question_length` and `sql_length`\n",
    "    df['question_length_norm'] = (df['question_length'] - df['question_length'].mean()) / df['question_length'].std()\n",
    "    df['sql_length_norm'] = (df['sql_length'] - df['sql_length'].mean()) / df['sql_length'].std()\n",
    "\n",
    "    # Display normalized features\n",
    "    df[['question_length_norm', 'sql_length_norm']].head()\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def extract_ctes(query):\n",
    "    # Matches patterns like: WITH alias AS ( ... )\n",
    "    # Using a non-greedy approach to capture each CTE block.\n",
    "    # This regex will find all occurrences of \"WITH ... AS ( ... )\" and subsequent CTEs \n",
    "    # if chained with commas.\n",
    "    cte_pattern = r'WITH\\s+(.*?)\\s+AS\\s*\\((.*?)\\)(?:,|$)'\n",
    "    # Using DOTALL to span multiple lines\n",
    "    matches = re.findall(cte_pattern, query, flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    ctes = {}\n",
    "    for alias, cte_subquery in matches:\n",
    "        alias = alias.strip()\n",
    "        ctes[alias.lower()] = cte_subquery\n",
    "    return ctes\n",
    "\n",
    "def extract_table_references(sql):\n",
    "    # This captures any word after FROM or JOIN. Adjust pattern if needed to match your table naming conventions.\n",
    "    return re.findall(r'(?:FROM|JOIN)\\s+([A-Za-z_][A-Za-z0-9_]*)', sql, flags=re.IGNORECASE)\n",
    "\n",
    "def extract_all_tables(query, known_tables):\n",
    "    # Extract CTEs first\n",
    "    ctes = extract_ctes(query)\n",
    "    \n",
    "    cte_aliases = set(ctes.keys())\n",
    "    all_tables = set()\n",
    "    \n",
    "    # Extract tables from each CTE definition\n",
    "    for cte_alias, cte_sql in ctes.items():\n",
    "        cte_tables = extract_table_references(cte_sql)\n",
    "        for tbl in cte_tables:\n",
    "            all_tables.add(tbl.lower())\n",
    "\n",
    "    # Now extract from the main query (after all CTEs)\n",
    "    # Strip the WITH clauses (optional, depends on how you parse)\n",
    "    # A crude approach: remove the WITH clauses and what follows until main SELECT\n",
    "    # If the query structure is stable, you can isolate the main query part.\n",
    "    main_query_part = re.split(r'WITH\\s+', query, flags=re.IGNORECASE|re.DOTALL)\n",
    "    if len(main_query_part) > 1:\n",
    "        # After splitting by WITH, the main query typically is after the last ) \n",
    "        # that closes the last CTE. We can try to find that:\n",
    "        main_query = re.split(r'\\)\\s*SELECT', query, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if len(main_query) > 1:\n",
    "            main_query = 'SELECT' + main_query[-1]  # re-attach SELECT\n",
    "        else:\n",
    "            # fallback if regex above doesn't isolate well\n",
    "            main_query = query\n",
    "    else:\n",
    "        # no WITH clause\n",
    "        main_query = query\n",
    "    \n",
    "    main_tables = extract_table_references(main_query)\n",
    "    for tbl in main_tables:\n",
    "        all_tables.add(tbl.lower())\n",
    "    \n",
    "    # Now we have all table-like references. Some are actual tables, some are CTE aliases.\n",
    "    # Filter them:\n",
    "    real_table_refs = [t for t in all_tables if t in known_tables]\n",
    "    cte_table_refs = [t for t in all_tables if t in cte_aliases]\n",
    "    invalid_refs = [t for t in all_tables if (t not in known_tables and t not in cte_aliases)]\n",
    "    \n",
    "    return real_table_refs, cte_table_refs, invalid_refs\n",
    "\n",
    "def validate_table_names(tables, table_names, cte_aliases=set()):\n",
    "    known_tables = set(t.lower() for t in tables)\n",
    "    return all((t in known_tables or t in cte_aliases) for t in map(str.lower, table_names))\n",
    "\n",
    "# def validate_table_names(tables, table_names):\n",
    "#     # Check if all table names are valid\n",
    "#     return all(table in tables for table in list(map(str.lower, table_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "with open(\"dev.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Load tables\n",
    "with open(\"dev_tables.json\", \"r\") as file:\n",
    "    tables = json.load(file)\n",
    "\n",
    "# Extract table names\n",
    "tablenames = set()\n",
    "for db in tables:\n",
    "    for table in db['table_names_original']:\n",
    "        tablenames.add(table.lower())\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>db_id</th>\n",
       "      <th>question</th>\n",
       "      <th>evidence</th>\n",
       "      <th>SQL</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>sql_length</th>\n",
       "      <th>difficulty_encoded</th>\n",
       "      <th>question_length</th>\n",
       "      <th>question_length_norm</th>\n",
       "      <th>sql_length_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>what is the highest eligible free rate for k-1...</td>\n",
       "      <td>eligible free rate for k-12 = `free meal count...</td>\n",
       "      <td>SELECT `Free Meal Count (K-12)` / `Enrollment ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.258897</td>\n",
       "      <td>0.210309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>please list the lowest three eligible free rat...</td>\n",
       "      <td>eligible free rates for students aged 5-17 = `...</td>\n",
       "      <td>SELECT `Free Meal Count (Ages 5-17)` / `Enroll...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.079876</td>\n",
       "      <td>1.348060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>please list the zip code of all the charter sc...</td>\n",
       "      <td>charter schools refers to `charter school (y/n...</td>\n",
       "      <td>SELECT T2.Zip FROM frpm AS T1 INNER JOIN schoo...</td>\n",
       "      <td>simple</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.258897</td>\n",
       "      <td>0.187554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>what is the unabbreviated mailing street addre...</td>\n",
       "      <td></td>\n",
       "      <td>SELECT T2.MailStreet FROM frpm AS T1 INNER JOI...</td>\n",
       "      <td>simple</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.616937</td>\n",
       "      <td>-0.324433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>please list the phone numbers of the direct ch...</td>\n",
       "      <td>charter schools refers to `charter school (y/n...</td>\n",
       "      <td>SELECT T2.Phone FROM frpm AS T1 INNER JOIN sch...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.079876</td>\n",
       "      <td>0.437860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id               db_id  \\\n",
       "0            0  california_schools   \n",
       "1            1  california_schools   \n",
       "2            2  california_schools   \n",
       "3            3  california_schools   \n",
       "4            4  california_schools   \n",
       "\n",
       "                                            question  \\\n",
       "0  what is the highest eligible free rate for k-1...   \n",
       "1  please list the lowest three eligible free rat...   \n",
       "2  please list the zip code of all the charter sc...   \n",
       "3  what is the unabbreviated mailing street addre...   \n",
       "4  please list the phone numbers of the direct ch...   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  eligible free rate for k-12 = `free meal count...   \n",
       "1  eligible free rates for students aged 5-17 = `...   \n",
       "2  charter schools refers to `charter school (y/n...   \n",
       "3                                                      \n",
       "4  charter schools refers to `charter school (y/n...   \n",
       "\n",
       "                                                 SQL difficulty  sql_length  \\\n",
       "0  SELECT `Free Meal Count (K-12)` / `Enrollment ...     simple         180   \n",
       "1  SELECT `Free Meal Count (Ages 5-17)` / `Enroll...   moderate         280   \n",
       "2  SELECT T2.Zip FROM frpm AS T1 INNER JOIN schoo...     simple         178   \n",
       "3  SELECT T2.MailStreet FROM frpm AS T1 INNER JOI...     simple         133   \n",
       "4  SELECT T2.Phone FROM frpm AS T1 INNER JOIN sch...   moderate         200   \n",
       "\n",
       "   difficulty_encoded  question_length  question_length_norm  sql_length_norm  \n",
       "0                   1               16              0.258897         0.210309  \n",
       "1                   2               15              0.079876         1.348060  \n",
       "2                   1               16              0.258897         0.187554  \n",
       "3                   1               18              0.616937        -0.324433  \n",
       "4                   2               15              0.079876         0.437860  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df[[\"SQL\", \"db_id\"]].iterrows():\n",
    "    # Extract tables from SQL\n",
    "    extracted_table_names = extract_all_tables(row.SQL, tablenames)\n",
    "    table_names, cte_aliases, invalid_refs = extracted_table_names\n",
    "    if not validate_table_names(tablenames, table_names, cte_aliases):\n",
    "        print(f\"Invalid table name in row {idx}: {table_names}\")\n",
    "        print(\"DB: \",row.db_id)\n",
    "        print(f\"\\t\\t{row.SQL}\")\n",
    "    # if invalid_refs:\n",
    "    #     print(f\"Invalid table reference in row {idx}: {invalid_refs}\")\n",
    "    #     print(\"DB: \",row.db_id)\n",
    "    #     print(f\"\\t\\t{row.SQL}\")\n",
    "    # if cte_aliases:\n",
    "    #     print(f\"CTE aliases in row {idx}: {cte_aliases}\")\n",
    "    #     print(\"DB: \",row.db_id)\n",
    "    #     print(f\"\\t\\t{row.SQL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_names = df.copy()\n",
    "df_table_names = df.drop(columns=[\"difficulty\",\"sql_length\", \"difficulty_encoded\", \"question_length\", \"question_length_norm\", \"sql_length_norm\"])\n",
    "df_table_names[\"table_names\"] = df_table_names[\"SQL\"].apply(lambda x: extract_all_tables(x, tablenames)[0])\n",
    "df_table_names[\"cte_aliases\"] = df_table_names[\"SQL\"].apply(lambda x: extract_all_tables(x, tablenames)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>db_id</th>\n",
       "      <th>question</th>\n",
       "      <th>evidence</th>\n",
       "      <th>SQL</th>\n",
       "      <th>table_names</th>\n",
       "      <th>cte_aliases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>what is the highest eligible free rate for k-1...</td>\n",
       "      <td>eligible free rate for k-12 = `free meal count...</td>\n",
       "      <td>SELECT `Free Meal Count (K-12)` / `Enrollment ...</td>\n",
       "      <td>[frpm]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>please list the lowest three eligible free rat...</td>\n",
       "      <td>eligible free rates for students aged 5-17 = `...</td>\n",
       "      <td>SELECT `Free Meal Count (Ages 5-17)` / `Enroll...</td>\n",
       "      <td>[frpm]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>please list the zip code of all the charter sc...</td>\n",
       "      <td>charter schools refers to `charter school (y/n...</td>\n",
       "      <td>SELECT T2.Zip FROM frpm AS T1 INNER JOIN schoo...</td>\n",
       "      <td>[schools, frpm]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>what is the unabbreviated mailing street addre...</td>\n",
       "      <td></td>\n",
       "      <td>SELECT T2.MailStreet FROM frpm AS T1 INNER JOI...</td>\n",
       "      <td>[schools, frpm]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>please list the phone numbers of the direct ch...</td>\n",
       "      <td>charter schools refers to `charter school (y/n...</td>\n",
       "      <td>SELECT T2.Phone FROM frpm AS T1 INNER JOIN sch...</td>\n",
       "      <td>[schools, frpm]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id               db_id  \\\n",
       "0            0  california_schools   \n",
       "1            1  california_schools   \n",
       "2            2  california_schools   \n",
       "3            3  california_schools   \n",
       "4            4  california_schools   \n",
       "\n",
       "                                            question  \\\n",
       "0  what is the highest eligible free rate for k-1...   \n",
       "1  please list the lowest three eligible free rat...   \n",
       "2  please list the zip code of all the charter sc...   \n",
       "3  what is the unabbreviated mailing street addre...   \n",
       "4  please list the phone numbers of the direct ch...   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  eligible free rate for k-12 = `free meal count...   \n",
       "1  eligible free rates for students aged 5-17 = `...   \n",
       "2  charter schools refers to `charter school (y/n...   \n",
       "3                                                      \n",
       "4  charter schools refers to `charter school (y/n...   \n",
       "\n",
       "                                                 SQL      table_names  \\\n",
       "0  SELECT `Free Meal Count (K-12)` / `Enrollment ...           [frpm]   \n",
       "1  SELECT `Free Meal Count (Ages 5-17)` / `Enroll...           [frpm]   \n",
       "2  SELECT T2.Zip FROM frpm AS T1 INNER JOIN schoo...  [schools, frpm]   \n",
       "3  SELECT T2.MailStreet FROM frpm AS T1 INNER JOI...  [schools, frpm]   \n",
       "4  SELECT T2.Phone FROM frpm AS T1 INNER JOIN sch...  [schools, frpm]   \n",
       "\n",
       "  cte_aliases  \n",
       "0          []  \n",
       "1          []  \n",
       "2          []  \n",
       "3          []  \n",
       "4          []  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved as 'processed_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save Processed Dataset\n",
    "# Save the processed dataset to a CSV file\n",
    "df_table_names.to_csv(\"tablenames_dataset.csv\", index=False)\n",
    "# Confirm save\n",
    "print(\"Processed dataset saved as 'processed_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & Overall Accuracy & Precision (Macro Avg) & Recall (Macro Avg) & F1 Score (Macro Avg) \\\\\n",
      "\\midrule\n",
      "RandomForest & 0.761733 & 0.497755 & 0.527802 & 0.488209 \\\\\n",
      "LogisticRegression & 0.722022 & 0.443354 & 0.452007 & 0.411678 \\\\\n",
      "NaiveBayes & 0.628159 & 0.206386 & 0.290850 & 0.236403 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.sparse import hstack  # For combining sparse matrices\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('tablenames_dataset.csv')\n",
    "\n",
    "# Preprocess the dataset\n",
    "df['input_text'] = df['db_id'] + \" \" + df['question'] + \" \" + df['evidence']\n",
    "df['primary_table'] = df['table_names'].apply(lambda x: eval(x)[0] if eval(x) else None)\n",
    "\n",
    "# Drop rows with missing input_text or primary_table values\n",
    "df_cleaned = df.dropna(subset=['input_text', 'primary_table'])\n",
    "\n",
    "# Prepare features and target\n",
    "X_text = df_cleaned['input_text']\n",
    "X_db = pd.get_dummies(df_cleaned['db_id'], sparse=True)  # One-hot encode db_id\n",
    "y = df_cleaned['primary_table']\n",
    "\n",
    "# Train-test split\n",
    "X_text_train, X_text_test, X_db_train, X_db_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_db, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize text input\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_text_train_vec = vectorizer.fit_transform(X_text_train)\n",
    "X_text_test_vec = vectorizer.transform(X_text_test)\n",
    "\n",
    "# Combine TF-IDF features with db_id encoding\n",
    "X_train_combined = hstack([X_text_train_vec, X_db_train])\n",
    "X_test_combined = hstack([X_text_test_vec, X_db_test])\n",
    "\n",
    "# Define baseline models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"NaiveBayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "baseline_results = {}\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_combined, y_train)\n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_combined)\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    baseline_results[name] = {\n",
    "        \"Overall Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision (Macro Avg)\": report[\"macro avg\"][\"precision\"],\n",
    "        \"Recall (Macro Avg)\": report[\"macro avg\"][\"recall\"],\n",
    "        \"F1 Score (Macro Avg)\": report[\"macro avg\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(baseline_results).T\n",
    "print(results_df.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
